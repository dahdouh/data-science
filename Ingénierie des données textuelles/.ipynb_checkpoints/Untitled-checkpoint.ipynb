{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"L'analyse syntaxique aussi bien que l'analyse 5061 en linguistique ont pour finalité de caractériser l'énoncé dans son ensemble, \n",
      "principalement par la détermination des structures de l'énoncé.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "document = \"\"\"\"L'analyse syntaxique aussi bien que l'analyse 5061 en linguistique ont pour finalité de caractériser l'énoncé dans son ensemble, \n",
    "principalement par la détermination des structures de l'énoncé.\n",
    "Dans les deux cas, la détermination des structures repose sur une caractérisation de ses éléments de base, \n",
    "les mots, et leurs propres constituants, \n",
    "mais de façon différente selon ces deux approches.\"\"\"\n",
    "phrases = sent_tokenize(document)\n",
    "print(phrases[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['``', \"L'analyse\", 'syntaxique', 'aussi', 'bien', 'que', \"l'analyse\", 'sémantique', 'en', 'linguistique', 'ont', 'pour', 'finalité', 'de', 'caractériser', \"l'énoncé\", 'dans', 'son', 'ensemble', ',', 'principalement', 'par', 'la', 'détermination', 'des', 'structures', 'de', \"l'énoncé\", '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(phrases[0])\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['``', \"L'ANALYSE\", 'SYNTAXIQUE', 'AUSSI', 'BIEN', 'QUE', \"L'ANALYSE\", 'SÉMANTIQUE', 'EN', 'LINGUISTIQUE', 'ONT', 'POUR', 'FINALITÉ', 'DE', 'CARACTÉRISER', \"L'ÉNONCÉ\", 'DANS', 'SON', 'ENSEMBLE', ',', 'PRINCIPALEMENT', 'PAR', 'LA', 'DÉTERMINATION', 'DES', 'STRUCTURES', 'DE', \"L'ÉNONCÉ\", '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = [w.upper() for w in tokens]\n",
    "print (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convertir un nombre numérique en mot\n",
      "['5061']\n",
      "Nombre après conversion \n",
      "\n",
      "['five thousand and sixty-one']\n"
     ]
    }
   ],
   "source": [
    "import inflect\n",
    "tokens = word_tokenize(phrases[0])\n",
    "\n",
    "print(\"convertir un nombre numérique en mot\")\n",
    "word = [word for word in tokens if word.isdigit()]\n",
    "print(word)\n",
    "\n",
    "p = inflect.engine()\n",
    "numbertransf = [p.number_to_words(word) for word in tokens if word.isdigit()]\n",
    "\n",
    "print (\"Nombre après conversion \\n\")\n",
    "print(numbertransf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['syntaxique', 'aussi', 'bien', 'que', 'en', 'linguistique', 'ont', 'pour', 'finalité', 'de', 'caractériser', 'dans', 'son', 'ensemble', 'principalement', 'par', 'la', 'détermination', 'des', 'structures', 'de']\n"
     ]
    }
   ],
   "source": [
    "# Suppression de tous les termes qui ne sont pas alphanumériques\n",
    "words_alpha = [word for word in tokens if word.isalpha()]\n",
    "print(words_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'ils', 'je', 'la', 'le', 'les', 'leur', 'lui', 'ma', 'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', 'à', 'm', 'n', 's', 't', 'y', 'été', 'étée', 'étées', 'étés', 'étant', 'étante', 'étants', 'étantes', 'suis', 'es', 'est', 'sommes', 'êtes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', 'étais', 'était', 'étions', 'étiez', 'étaient', 'fus', 'fut', 'fûmes', 'fûtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'fût', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'eûmes', 'eûtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'eût', 'eussions', 'eussiez', 'eussent']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/karim/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "#stop_words = stopwords.words('english')\n",
    "#print(stop_words)\n",
    "stop_words = stopwords.words('french')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple d'application des stopwords\n",
      "\n",
      "Avant transformation \n",
      "\n",
      "['syntaxique', 'aussi', 'bien', 'que', 'en', 'linguistique', 'ont', 'pour', 'finalité', 'de', 'caractériser', 'dans', 'son', 'ensemble', 'principalement', 'par', 'la', 'détermination', 'des', 'structures', 'de']\n"
     ]
    }
   ],
   "source": [
    "print (\"Exemple d'application des stopwords\\n\")\n",
    "tokens = word_tokenize(phrases[0])\n",
    "tokens = [w.lower() for w in tokens]\n",
    "words = [word for word in tokens if word.isalpha()]\n",
    "print (\"Avant transformation \\n\")\n",
    "print (words)\n",
    "\n",
    "stop_words = set(stopwords.words('french'))\n",
    "words = [w for w in words if not w in stop_words]\n",
    "print (\"\\n Après transformation \\n\")\n",
    "print(words)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
